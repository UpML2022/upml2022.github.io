<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
            "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width">
  <title>UpML 2022 – Updatable Machine Learning</title>

  <link href="style.css" type="text/css" rel='stylesheet'>
  <link rel='stylesheet' media='screen and (max-width: 750px)'
  href='narrow.css'>
</head>

<body>

<div id="header">
  <h1>UpML 2022 – Updatable Machine Learning</h1>
  <h2>Baltimore - 23 July 2022 - part of <a
  href="https://icml.cc/Conferences/2022/">ICML 2022</a>
  <br>
  </h2>
</div>

<div class="program box"> <h2>Program (tentative)
</h2>
<p>
(All listed times are EST)
</p>
<table  style="padding:15px; column-gap:1000px">

  <tr>
    <td>
      8:55-9:00
    </td>
    <td></td>
    <td>
       Opening Remarks
      <br>
    </td>
  </tr>

  <tr>
    <td>
      9:00-9:30
    </td>
    <td></td>
    <td>
      <strong>Planting undetectable backdoors in Machine Learning models</strong>
      <br>
    <a href="https://www.cs.tau.ac.il/~orzamir/">Or Zamir</a> (Invited Speaker)
      <br>
    </td>
  </tr>
  

  <tr>
    <td>
      9:30-10:00
    </td>
    <td></td>
    <td>
      <strong>An Algorithmic Framework for Bias Bounties</strong>
      <br>
      <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a> (Invited Speaker)
      <br>
    </td>
  </tr>

  
  
  <tr>
    <td>
      10:00-10:30
    </td>
    <td></td>
    <td>
    Break
   </td>
  </tr>


  <tr>
    <td>
      10:30-11:30
    </td>
    <td></td>
    <td>
    <strong>Spotlight talks 1</strong>
      <br> 
      <br>
      From Adaptive Query Release to Machine Unlearning
      <br>
      Enayat Ullah, Raman Arora
      <br> 
      <br>
      Geometric Alignment Improves Fully Test Time Adaptation      
      <br>
      Kowshik Thopalli, Pavan K. Turaga, Jayaraman J. Thiagarajan 
      <br> 
      <br>
      Modeling the Right to Be Forgotten
      <br>
      Aloni Cohen, Adam Smith, Marika Swanberg, Prashant Nalini Vasudevan
      <br> 
      <br>
      Revisiting the Updates of a Pre-trained Model for Few-shot Learning
      <br>
      Yujin Kim, Jaehoon Oh, Sungnyun Kim, Se-Young Yun
      <br> 
      <br>
      <a href="https://drive.google.com/file/d/1cZbhJnN4KtD7k7VIAXHipGhro837rtV3/view?usp=sharing">Super Seeds: extreme model compression by trading off storage with computation </a>   
      <br>
      Nayoung Lee*, Shashank Rajput*, Jy-yong Sohn, Hongyi Wang, Alliot Nagle, Eric Xing, Kangwook Lee, Dimitris Papailiopoulos (*: equal contribution)
      <br> 
      <br>
      <a href="https://arxiv.org/pdf/2206.01626.pdf">Beyond Tabula Rasa: Reincarnating Reinforcement Learning</a>
      <br>
      Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron Courville, Marc G Bellemare
    </td>
  </tr>
  
  <tr>
    <td>
      11:30-12:00
    </td>
    <td></td>
    <td>
      <strong>Adapting Deep Networks to Distribution Shift with Minimal Assumptions</strong>
      <br>
      <a href="https://scholar.google.com/citations?user=vfPE6hgAAAAJ&hl=en">Chelsea Finn</a> (Invited Speaker)
      <!-- <a href="https://scholar.google.com/citations?user=vfPE6hgAAAAJ&hl=en">Chelsea Finn</a> and <a href="https://ericmitchell.ai/">Eric Anthony Mitchell</a> (Invited Speakers) --> 
      <br>
    </td>
  </tr>


    <tr>
    <td>
      12:00-1:30
    </td>
    <td></td>
    <td>
    Lunch break 
      <br>
    </td>
  </tr>


  <tr>
    <td>
      1:30-2:00
    </td>
    <td></td>
    <td>
      <strong>What does it mean to unlearn?</strong>
      <br>
      <a href="https://www.papernot.fr/">Nicolas Papernot</a> (Invited Speaker)
      <br>
    </td>
  </tr>


  <tr>
    <td>
      2:00-2:30
    </td>
    <td></td>
    <td>
      <strong> Test-time adaptation via the convex conjugate </strong>
      <br>
      <a href="https://zicokolter.com/">Zico Kolter</a> (Invited Speaker)
      <br>
    </td>
  </tr>

  <tr>
    <td>
      2:30-3:00
    </td>
    <td></td> 
    <td>
    <strong>Spotlight talks 2</strong> 
      <br> 
      <br>
      <a href="https://arxiv.org/abs/2203.10079">Simulating Bandit Learning from User Feedback for Extractive Question Answering</a>
      <br>
      Ge Gao, Eunsol Choi, Yoav Artzi

      <br> 
      <br>
      How Adaptive are Adaptive Test-time Defenses?      
      <br>
      Francesco Croce, Sven Gowal, Thomas Brunner, Evan Shelhamer, Matthias Hein, Ali Taylan Cemgil

      <br> 
      <br>
      <a href="https://arxiv.org/abs/2207.03442">Comparing Model and Input Updates for Test-Time Adaptation to Corruption</a>      
      <br>
      Jin Gao, Jialing Zhang, Xihui Liu, Trevor Darrell, Evan Shelhamer, Dequan Wang

    </td>

  </tr>
  

  <tr>
    <td>
      3:00-3:30
    </td>
    <td></td>
    <td>
    Break
      <br>
    </td>
  </tr>

  <tr>
    <td>
      3:30-5:30
    </td>
    <td></td>
    <td>
Poster Session 
      <br>
    </td>
  </tr>


  <!-- <tr>
    <td>
      3:30-5:30
    </td>
    <td></td>
    <td>
      <a href="https://arxiv.org/abs/2201.05964">Visualizing Privacy-Utility Trade-Offs in Differentially Private Data Releases</a>
      <br>
      Priyanka Nanayakkara, Johes Bater, Xi He, Jessica Hullman, Jennie Rogers
      <br>
      <br>
      Widespread Underestimation of Sensitivity in Differentially Private Libraries and How to Fix It
      <br>
      Sílvia Casacuberta, Michael Shoemate, Salil Vadhan, Connor Wagaman
    </td>
  </tr> -->

</table>
</div>

<div class="content box"> <h2>Accepted Papers</h2>
  <p>
  Accepted papers will be presented as in-person posters or pre-recorded lightning talks.
  Additionally, nine papers were selected as spotlight talks (all of which will be in person).
  </p>

  <p><b>
    Poster Session:
  </b></p>
  <ul>
   <!-- <li>2<br></li> 
    <li>4<br></li> 
    <li>5<br></li>      
    <li>7<br></li> 
    <li>9<br></li> 
    <li>10<br></li> 
    <li>11<br></li> 
    <li>12<br></li> 
    <li>15<br></li>
    <li>16<br></li> 
    <li>19<br></li> 
    <li>20<br></li> 
    <li>22<br></li>
    <li>23<br></li>
    <li>25<br></li> 
    <li>31<br></li> 
    <li>32<br></li>
    <li>33<br></li> -->
    <li>  <a href="https://arxiv.org/abs/2205.05282">ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot Learning</a><br>Jaehoon Oh, Sungnyun Kim, Namgyu Ho, Jin-Hwa Kim, Hwanjun Song, Se-Young Yun</li> 
    <li> <a href="https://drive.google.com/file/d/1tatIeI5jQ6PP7qu2eYlrQyr3euimqsf7/view?usp=sharing">Geometric Alignment Improves Fully Test Time Adaptation</a><br>Kowshik Thopalli, Pavan K. Turaga, Jayaraman J. Thiagarajan</li> 
    <li>  <a href="https://arxiv.org/abs/2205.06905">Perspectives on Incorporating Expert Feedback into Model Updates</a><br>Valerie Chen, Umang Bhatt, Hoda Heidari, Adrian Weller, Ameet Talwalkar</li>      
    <li><a href="https://arxiv.org/abs/2106.03027">Model Zoo: A Growing "Brain" That Learns Continually</a><br>Rahul Ramesh, Pratik Chaudhari</li> 
    <li>Modeling the Right to Be Forgotten<br>Aloni Cohen, Adam Smith, Marika Swanberg, Prashant Nalini Vasudevan</li> 
    <li> From Adaptive Query Release to Machine Unlearning<br>Enayat Ullah, Raman Arora</li> 
    <li> <a href="https://arxiv.org/abs/2204.07655">Deep Unlearning via Randomized Conditionally Independent Hessians</a><br>Ronak Mehta, Sourav Pal, Vikas Singh, Sathya N. Ravi</li> 
    <li>  <a href="https://arxiv.org/abs/2206.02659">Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees</a><br>Haotian Ju, Dongyue Li, Hongyang R Zhang</li>
    <li><a href="https://arxiv.org/abs/2201.02692">Improved Input Reprogramming for GAN Conditioning</a><br>Tuan Dinh, Daewon Seo, Zhixu Du, Liang Shang, Kangwook Lee</li> 
    <li><a href="https://arxiv.org/abs/2205.07874">Revisiting the Updates of a Pre-trained Model for Few-shot Learning</a><br>Yujin Kim, Jaehoon Oh, Sungnyun Kim, Se-Young Yun</li> 
    <li>  Simulating Bandit Learning from User Feedback for Extractive Question Answering<br>Ge Gao, Eunsol Choi, Yoav Artzi</li> 
    <li><a href="https://drive.google.com/file/d/1qV2VCSfZaiZeFy3yJRYS8FY8H4T7g-kR/view?usp=sharing">Updating Object Detection Models with Probabilistic Programming</a><br>Martijn Oldenhof, Adam Arany, Yves Moreau, Edward De Brouwer</li>
    <li>  <a href="https://arxiv.org/pdf/2207.05521.pdf">Federated Unlearning: How to Efficiently Erase a Client in FL?</a><br>Anisa Halimi, Swanand Kadhe, Ambrish Rawat, Nathalie Baracaldo</li>
    <li><a href="https://drive.google.com/file/d/1cZbhJnN4KtD7k7VIAXHipGhro837rtV3/view?usp=sharing">Super Seeds: extreme model compression by trading off storage with computation</a><br>Nayoung Lee*, Shashank Rajput*, Jy-yong Sohn, Hongyi Wang, Alliot Nagle, Eric Xing, Kangwook Lee, Dimitris Papailiopoulos
(*: equal contribution)</li> 
    <li>Beyond Tabula Rasa: Reincarnating Reinforcement Learning<br>Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron Courville, Marc G Bellemare</li> 
    <li><a href="https://arxiv.org/abs/2202.13711">How Adaptive are Adaptive Test-time Defenses?</a><br>Francesco Croce, Sven Gowal, Thomas Brunner, Evan Shelhamer, Matthias Hein, Ali Taylan Cemgil</li>
    <li>Comparing Model and Input Updates for Test-Time Adaptation to Corruption<br>Jin Gao, Jialing Zhang, Xihui Liu, Trevor Darrell, Evan Shelhamer, Dequan Wang</li>
  </ul>

  <p><b>
    Virtual poster presentations (2 minute videos):
  </b></p>
  <ul>
    <!-- <li>1<br></li> 
    <li>3<br></li> 
    <li>6<br></li>      
    <li>13<br></li> 
    <li>17<br></li> 
    <li>21<br></li> 
    <li>24<br></li> 
    <li>27<br></li> --> 
    <li> <a href="https://arxiv.org/abs/2206.14607v1">NERDA-Con: Extending NER models for Continual Learning — Integrating Distinct Tasks and Updating Distribution Shifts</a><br>Supriti Vijay, Aman Priyanshu (<a href="https://youtu.be/3WritRdU62Y">video</a>)</li> 
    <li>  <a href="https://drive.google.com/file/d/1fLjv1iGjU2Dfm9p91lNsUcHasXr42uW-/view?usp=sharing">Similarity of Pretrained and Fine-tuned Representations</a><br>Thomas Goerttler, Klaus Obermayer (<a href="https://youtu.be/lfV4od5ebYo">video</a>)</li>
    <li>  <a href="https://arxiv.org/abs/2203.08850">Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for Low-Resource Language Translation?</a><br>En-Shiun Annie Lee, Sarubi Thillainathan, Shravan Nayak, Surangika Ranathunga, David Ifeoluwa Adelani, Ruisi Su, Arya D. McCarthy (<a href="https://www.youtube.com/watch?v=oFlhqPNEwaA">video</a>)</li>  
    <li><a href="https://drive.google.com/file/d/1PO0BgHl-isa2IVLDokqXf1TNOXKtLLpW/view?usp=sharing">Evaluating Online Bayesian Inference in Sample-Based Approximate BNNs</a><br>Andreas Kirsch, Jannik Kossen, Yarin Gal (<a href="https://youtu.be/mBTYVhAjpPw">video</a>, <a href="https://arxiv.org/abs/2205.08766">arXiv</a>)</li>
    <li> <a href="https://arxiv.org/abs/2202.08821">Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness</a><br>Kate Donahue, Alexandra Chouldechova, Krishnaram Kenthapadi (<a href="https://youtu.be/06NZ7dk3lgM">video</a>)</li> 
    <li>  <a href="https://drive.google.com/file/d/19cE5UsNG0V-KFpoLyJKr90BADeEiFerP/view?usp=sharing">Updatable Clustering Via Patches</a><br>Anshuman Chhabra, Ashwin Sekhari, Prasant Mohapatra</li> 
    <li>  <a href="https://arxiv.org/abs/2206.13607">Improved Text Classification via Test-Time Augmentation</a><br>Helen Lu, Divya M Shanmugam, Harini Suresh, John Guttag (<a href="https://youtu.be/gmLD62fgVYY">video</a>)</li> 
    <li>  <a href="https://arxiv.org/pdf/2207.03227.pdf">Challenges and Pitfalls of Bayesian Unlearning</a><br>Ambrish Rawat, James Requeima, Wessel Bruinsma, Richard E Turner</li> 
    <li><a href="https://arxiv.org/pdf/2206.08489.pdf">Debugging using Orthogonal Gradient Descent</a><br>Narsimha Reddy Chilkuri, Chris Eliasmith (<a href="https://youtu.be/htcacYcYhic">video</a>)</li> 
  </ul>


  <ul>
  </ul>

</div>

<div class="content box"> <h2>Context</h2>

<p>
In modern ML domains, state-of-the-art performance is attained by highly overparameterized models that are expensive to train, costing weeks of time and millions of dollars. At the same time, after deploying the model, the learner may realize issues such as leakage of private data or vulnerability to adversarial examples. The learner may also wish to impose additional constraints post-deployment, for example, to ensure fairness for different subgroups. Retraining the model from scratch to incorporate additional desiderata would be expensive. As a consequence, one would instead prefer to update the model, which can yield significant savings of resources such as time, computation, and memory over retraining from scratch. Some instances of this principle in action include the emerging field of machine unlearning, and the celebrated paradigm of fine-tuning pretrained models. The goal of our workshop is to provide a platform to stimulate discussion about both the state-of-the-art in updatable ML and future challenges in the field.
</p>  

<p>
This workshop will bring together researchers from various ML communities to discuss recent theoretical and empirical developments in updatable machine learning
</p>

<p>
Specific topics of interest for the workshop include (but are not limited to) theoretical and empirical works in:
<ul>
<li>Methods to update a trained model post-deployment for:</li>
<ul>
<li>Robustness to corruptions</li>  
<li>Fairness</li>
<li>Domain shifts</li>
<li>Privacy</li>
<li>Additional safety constraints</li>
</ul>
<li>Machine unlearning</li>
<li>Resource efficient model fine-tuning</li>
<li>Model updates under communication constraints</li>
<li>Efficient training and deployment of updatable ML systems</li>
<li>Memory / computation tradeoffs in updatable ML</li>
<li>Threats to updatable ML systems and possible fixes</li>
<li>Long-term and societal impacts of updatable ML systems</li>
<li>Ensemble methods for efficient model updates</li>
</ul>
</p>

</div>

<div class="content box">
<h2 id="submission">Submission</h2>

<p>
The goal of UpML is to bring together researchers from various theoretical and applied ML communities working on topics related to post deployment modification of a trained model. We seek contributions from different research areas of computer science, and statistics.
</p>

<p>
Authors are invited to submit a short abstract (4 pages of main content + unlimited pages for references) of their work. Submissions are single-blind (non-anonymized), and there is no prescribed style file (though authors should be considerate of reviewers in their selection). Supplementary material (proofs, additional experiments, etc) can be included after the references but it is not expected that the authors will review the content beyond the first 4 pages. The authors can also provide a link pointing to the full version of the paper.  
</p>

<p>
Submissions will undergo a lightweight review process and will be judged on originality, relevance, interest and clarity. Submission should describe novel work or work that has already appeared elsewhere but that can stimulate the discussion between different communities at the workshop. Accepted abstracts will be presented at the workshop either as a talk or a poster.
</p>

<p>
The workshop will not have formal proceedings and is not intended to preclude later publication at another venue. We will be posting links to accepted papers publicly on the workshop website (if the authors of that paper want to). 

</p>

<!-- <p>
  Selected papers from the workshop will be invited to submit a full version of their work for publication in a <a href="https://journalprivacyconfidentiality.org/index.php/jpc/tpdp">special issue</a> of the <a href="https://journalprivacyconfidentiality.org/index.php/jpc">Journal of Privacy and Confidentiality</a>.
</p>
 -->
<p>
  <a href="./CFP.pdf">Call for Papers (PDF)</a>
</p>
</div>


<div class="side box">
<h2>Invited Speakers</h2>
<ul>
    <li >
  <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a> <br>
 Stanford University
  </li>
  <li>
<a href="http://people.csail.mit.edu/shafi/">Shafi Goldwasser</a> <br>
    Simons Institute / UC Berkeley  
  </li>
   <li >
  <a href="https://zicokolter.com/">Zico Kolter</a> <br>
Carnegie Mellon University
  </li>
  <li> 
    <a href="https://www.papernot.fr/">Nicolas Papernot</a> <br>
    University of Toronto
  </li>
  <li>
    <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a> <br>
    University of Pennsylvania
  </li>
</ul>
</div>


<div class="side box">
  <h2>Important Dates</h2>
  <dl>
    <dt>Abstract Submission</dt>

    <dd>Monday, May 16, 2022 (11:59 PM)</dd>
   
    <dt>Notification</dt>
      <dd>Monday, June 13, 2022</dd>
    <dt>Workshop</dt>
    <dd>July 23, 2022</dd>
  </dl>
</div>




<div class="side box">
  <h2>Organizing and Program Committee</h2>
  <ul>
    <li class="pc">
      <a href="https://www.cs.cornell.edu/~sekhari/">Ayush Sekhari</a> (co-chair)<br>
      Cornell University
    </li>
    <li class="pc">
      <a href="http://www.gautamkamath.com/">Gautam Kamath</a> (co-chair)<br>
      University of Waterloo
    </li>
    <li class="pc">
      <a href="https://people.ece.cornell.edu/acharya/">Jayadev Acharya</a> (co-chair)<br>
      Cornell University
    </li>
<!-- PC Members -->
    <li class="pc">
      <a href="https://theertha.info/">Ananda Theertha Suresh</a><br>
      Google Research 
    </li>  
        <li class="pc">
      <a href="https://sites.google.com/site/anupraob/">Anup Rao</a><br>
      Adobe Research 
    </li>    
<li class="pc">
      <a href="https://www.ashudeepsingh.com/">Ashudeep Singh</a><br>
      Pinterest Labs  
    </li>    
 <li class="pc">
      <a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a><br>
      Google Research 
    </li>    
 <li class="pc">
      <a href="https://pluskid.org/">Chiyuan Zhang</a><br>
      Google Research 
 </li>    
  <li class="pc">
      <a href="https://sites.google.com/view/chuanguo">Chuan Guo</a><br>
      Meta Research 
  </li>  
  <li class="pc">
      <a href="https://dayu11.github.io/">Da Yu</a><br>
      Sun Yat-sen University/MSR Asia  
  </li> 
  <li class="pc">
      <a href="https://edwardjhu.com/about/">Edward Hu</a><br>
      MILA  
  </li>  
  <li class="pc">
      <a href="https://www.emilyruthdiana.com/">Emily Diana</a><br>
      University of Pennsylvania  
  </li>  
  <li class="pc">
      <a href="https://enayatullah.github.io/">Enayat Ullah</a><br>
      Johns Hopkins University  
  </li>  
  <li class="pc">
      <a href="https://hadisalman.com/">Hadi Salman</a><br>
      MIT  
  </li>  
  <li class="pc">
      <a href="https://huanyuzhang.github.io/">Huanyu Zhang</a><br>
      Meta Research 
  </li>  
  <li class="pc">
      <a href="https://globusharris.github.io/">Ira Globus-Harris</a><br>
       University of Pennsylvania
  </li>  
  <li class="pc">
      <a href="http://www.cs.cornell.edu/~sridharan/">Karthik Sridharan</a><br>
       Cornell University
  </li> 
  <li class="pc">
      <a href="https://www.katedonahue.me/">  
Kate Donahue</a><br>
       Cornell University
  </li> 
  <li class="pc">
      <a href="https://home.ttic.edu/~kstangl/">  
Kevin Matthew Stangl</a><br>
       TTIC
  </li> 
  <li class="pc">
      <a href="https://ttic.uchicago.edu/~omar/">  
Omar Montasser</a><br>
       TTIC
  </li> 
  <li class="pc">
      <a href="http://cs.stanford.edu/~pangwei">  
  Pang Wei Koh</a><br>
       Stanford
  </li> 
  <li class="pc">
      <a href="https://kairouzp.github.io/">  
  Peter Kairouz</a><br>
       Google Research
  </li> 
  <li class="pc">
      <a href="https://sites.google.com/view/saeedsh/home">  
 Saeed Sharifi-Malvajerdi</a><br>
       University of Pennsylvania
  </li> 
  <li class="pc">
      <a href="https://urmish.github.io/">  
Urmish Thakker</a><br>
      SambaNova Systems
  </li> 
  <li class="pc">
      <a href="https://scholar.google.com/citations?user=B8UeYcEAAAAJ&hl=en">  
Varsha Kishore</a><br>
      Cornell University
  </li> 
  <li class="pc">
      <a href="http://www.zitengsun.com/">  
Ziteng Sun</a><br>
    Google Research 
   </li> 
 <br>
   <!--  <li class="pc">
      More PC members coming... 
    </li> -->
  </ul>
</div>

<div class="side box">
  <h2>Contact</h2>

<a href="mailto:upml2022workshop@gmail.com">upml2022workshop@gmail.com</a>

  <br>
  <br>

</div>

<div class="side box">
  <h2>Submission website</h2>
  <br>
  <a href="https://openreview.net/group?id=ICML.cc/2022/Workshop/UpML">OpenReview</a>
  <br>
  <br>

<!-- TPDP 2022 - Theory and Practice of Differential Privacy --> 

<!--    Note the “open” features of OpenReview will not be used, and visibility of all submissions,
reviews, and accepted papers will be restricted to the program committee (similar other systems
like EasyChair, CMT, HotCRP, etc.). --! 
  <br>
  <br>
</div>


<div id="bg_descr">
</div>

</body></html>
